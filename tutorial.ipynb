{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this tutorial, you can learn about OpenAI Assistant and explore its capabilities further.\n",
    "\n",
    "## table of content\n",
    ">- What is OpenAI assistant?\n",
    ">- Leveraging LangChain to utilize OpenAI Assistant capabilities.\n",
    ">- Combining OpenAI Assistant and LangChain tool to extend capabilities in the context of OpenAI Assistant.\n",
    "\n",
    "## What is OpenAI assistant?\n",
    "The Assistants API enables the creation of AI assistants directly within your applications. These assistants are equipped with instructions and can utilize various models, tools, and knowledge to provide responses to user inquiries. Currently, the Assistants API supports three categories of tools: \n",
    "1. Code Interpreter\n",
    "2. Retrieval\n",
    "3. Function Calling\n",
    "\n",
    "For more details follow [LangChain](https://python.langchain.com/docs/modules/agents/agent_types/openai_assistants) and [OpenAI assistants](https://platform.openai.com/docs/assistants/overview)\n",
    "\n",
    "### Project info\n",
    "Let's create a research assistant! `ScholarlySphere` is a Document Analysis and Search assistant.\n",
    "Users can upload PDF or text files containing documents or research papers. `ScholarlySphere` can then extract key information, such as keywords, topics, or main points, and use search engines to find relevant information to answer user questions based on the content of the uploaded files.\n",
    "\n",
    "\n",
    "## Leveraging LangChain to utilize OpenAI Assistant capabilities\n",
    "Let's craft our own AI assistant!🚀\n",
    "\n",
    "In this step we want to create an assistant that use search engines to find relative data about user query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import some packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable # import OpenAIAssistantRunnable from langchain\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.tools import DuckDuckGoSearchResults, DuckDuckGoSearchRun\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to have an openAI API key\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need an instruction. An instruction is how the Assistant and model should behave or respond.\n",
    "instructions = \"\"\"\n",
    "    You are a scholarly expert, you have the skill to find academic papers similar to users' \n",
    "    provided papers and utilize online resources to find similar papers. Your expertise enables you\n",
    "    to generate comprehensive outputs based on user desires.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# What we need in the output?\n",
    "prompt = \"\"\"\n",
    "    Give structured JSON output involved 5 references that explation GPT-3:\n",
    "      title, author_names, content_summary are the fields.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To connect our agent to online resources we need some search engine as tools.\n",
    "# create the search tool based on new sholars\n",
    "tools = [DuckDuckGoSearchRun()]\n",
    "\n",
    "# create the agent of assistant-openai\n",
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"Document Analysis and Search assistant\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With AgentExecutor:\n",
    "The `OpenAIAssistantRunnable` works well with `AgentExecutor`, so we can easily include it as an agent directly in the executor. The AgentExecutor handles running the tools we use and sending their results back to the Assistants API. It also includes LangSmith tracing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)\n",
    "output = agent_executor.invoke({\"content\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the search results, here are five references that provide an explanation of GPT-3. Below, I've structured the JSON output as requested with some of the details available from the description:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Capabilities of GPT Series Models\",\n",
      "    \"author_names\": [\"Not Provided\"],\n",
      "    \"content_summary\": \"This paper analyzes the capabilities of various GPT series models, including GPT-3 and GPT-3.5. The study includes multiple iterations like davinci and text-davinci, highlighting the advances in language modeling that these versions represent.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"The Role of GPT Systems as Co-authors in Academic Paper Writing\",\n",
      "    \"author_names\": [\"Not Provided\"],\n",
      "    \"content_summary\": \"This study investigates the potential of a system to act as a co-author on an academic paper. The authors focus on the criteria set by the International Committee of Medical Journal Editors (ICMJE) and explore the impact of GPT models in aiding research work and writing processes.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Introduction to GPT-3 and Transformer Architecture\",\n",
      "    \"author_names\": [\"Vaswani et al. (Citing)\"],\n",
      "    \"content_summary\": \"This paper discusses the GPT-3 model and its underlying Transformer architecture, introduced by Vaswani et al. in 2017. The authors note GPT-3's significant size, with 175 billion parameters, and its role in advancing natural language processing tasks.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Survey on the GPT-3 Family and Large Language Models\",\n",
      "    \"author_names\": [\"Not Provided\"],\n",
      "    \"content_summary\": \"The survey covers the evolution and increasing popularity of Large Language Models (LLMs), starting with OpenAI's GPT-3. The paper serves as a resource for academics and industry professionals to stay abreast of the latest research and developments in the field.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Advancements in Academic Writing with GPT Models\",\n",
      "    \"author_names\": [\"Not Provided\"],\n",
      "    \"content_summary\": \"The paper explores the advanced language models represented by GPT, focusing on their significant impact on academic writing. By offering support in idea generation, drafting, and overcoming writer's block, GPT models have become invaluable tools in research and writing.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that specific author names were not provided for most references in the search results summary, and the content summaries are constructed based on the limited information available from the search result descriptions. For complete information, including accurate authorship, it is recommended to access the full academic papers.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed an assistant capable of accessing real-time data through search tools. For additional tools, you can refer to the [LangChain Tools](https://python.langchain.com/docs/integrations/tools) documentation.\n",
    "\n",
    "\n",
    "## Combining OpenAI Assistant and LangChain tool\n",
    "Occasionally, we possess existing data and wish for LLMs to not only access real-time data but also utilize files to gather information.\n",
    "\n",
    "In this step we extract key main points of a PDF file, and use search engines to find relevant information to answer user questions based on the content of the uploaded files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need an instruction. An instruction is how the Assistant and model should behave or respond.\n",
    "instructions = \"\"\"\n",
    "    You are a scholarly expert, you have the skill to extract crucial details from academic papers provided \n",
    "    for you and utilize online resources to find similar papers. Your expertise enables you\n",
    "    to generate comprehensive outputs based on user desires.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# What we need in the output?\n",
    "file_prompt = \"\"\"\n",
    "    Write a detailed summary of the input paper, synthesizing its key findings, methodologies, and \n",
    "    implications, providing overview for reference and comprehension purposes.\"\"\"\n",
    "\n",
    "\n",
    "online_prompt = \"\"\"\n",
    "    Give structured JSON file for similar papers that you found contains: paper_title, authors_names, \n",
    "    publication_date, link_of_paper and the conference_or_journal_name where it was published.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filrst we need to initiate OpenAI client instance\n",
    "client = OpenAI()\n",
    "\n",
    "# Upload a file with an \"assistants\" purpose\n",
    "file = client.files.create(\n",
    "  file=open(\"attention_is_all_you_need.pdf\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# Add the file to the assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Document Analysis and Search assistant\",\n",
    "  instructions=instructions,\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\": \"retrieval\"}], # \n",
    "  file_ids=[file.id]\n",
    ")\n",
    "\n",
    "# create a thread\n",
    "thread = client.beta.threads.create()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=file_prompt,\n",
    "  file_ids=[file.id]\n",
    ")\n",
    "\n",
    "create_run_10 = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "retrieve_run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=create_run_10.id\n",
    ")\n",
    "\n",
    "responses = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Write a detailed summary of the input paper, synthesizing its key findings, methodologies, and \n",
      "    implications, providing overview for reference and comprehension purposes.\n",
      "The paper delves into the specifics of the Transformer model, explaining its core components and advantages. A significant innovation within the Transformer is the use of \"Multi-Head Attention.\" This approach employs multiple attention functions in parallel to allow the model to capture information from different representation subspaces at various positions. Each 'head' focuses on a different part of the encoded information, enabling the model to pay attention to diverse parts of a sequence simultaneously【15†source】.\n",
      "\n",
      "In addition, the Transformer features \"Position-wise Feed-Forward Networks\" applied identically to each position, consisting of two linear transformations with a ReLU activation in between. These networks contribute to learning local patterns within the sequence data【16†source】.\n",
      "\n",
      "A key element that enables the Transformer to understand the order of a sequence, despite the absence of recurrence and convolution, is \"Positional Encoding.\" The model uses sine and cosine functions of different frequencies to encode positional information, facilitating the model's capacity to learn and utilize the order of sequences. The choice of sinusoidal positional encoding over learned positional embeddings is mainly because it may allow the model to extrapolate to sequence lengths not encountered during training【16†source】.\n",
      "\n",
      "The paper also explains why the authors chose self-attention as a central mechanism. Self-attention offers numerous benefits over recurrent and convolutional layers, including lower overall computational complexity per layer, more potential for parallelization, and shorter path lengths between positions in a sequence. Shorter paths enhance the ability to learn long-range dependencies, which is crucial in sequence transduction tasks【17†source】.\n",
      "\n",
      "The core methodological contributions of the Transformer include these multi-head attention mechanisms along with positional encodings and feed-forward networks, which when combined, yield a powerful model architecture capable of achieving state-of-the-art results in sequence transduction tasks like machine translation. The Transformer's architecture facilitates more parallelizable computation and shorter training times compared to its predecessors, and its results on translation tasks underscore its effectiveness.\n",
      "\n",
      "If the user would like to go deeper into any specific section of the paper or has further questions pertaining to certain methodologies or findings, I am at disposal to provide a more detailed synopsis and further analysis.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the list of messages\n",
    "for message in responses.data[:2]:\n",
    "        print(message.content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use an existing Assistant we can initialize the OpenAIAssistantRunnable directly with an assistant_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To connect our agent to online resources we need some search engine as tools.\n",
    "# create the search tool based on new sholars\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(time=\"m\")\n",
    "tools = [DuckDuckGoSearchResults(api_wrapper=wrapper, source=\"scholar\")]\n",
    "\n",
    "# create the agent of assistant-openai\n",
    "agent = OpenAIAssistantRunnable(\n",
    "    tools=tools,\n",
    "    assistant_id=assistant.id,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)\n",
    "output = agent_executor.invoke({\"content\": online_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To assist you, I will need to first review the content of the uploaded academic paper to understand its topic, scope, and specifics. After assessing the content, I can then utilize online resources to locate similar papers and provide the structured JSON information you've requested.\n",
      "\n",
      "I will now examine the uploaded document to understand its subject matter. Please bear with me for a moment as I access the file.\n",
      "The paper provided is \"Attention Is All You Need,\" which details the development of the Transformer model architecture for sequence transduction models (e.g., machine translation). Here are the details extracted from the paper:\n",
      "\n",
      "- **Paper Title**: Attention Is All You Need\n",
      "- **Authors' Names**: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin\n",
      "- **Publication Date**: 2 August 2023\n",
      "- **Conference or Journal Name**: 31st Conference on Neural Information Processing Systems (NIPS 2017)\n",
      "- **Link of Paper**: The paper is an arXiv manuscript with the identifier arXiv:1706.03762v7 [cs.CL]【8†source】.\n",
      "\n",
      "I will now search for similar papers that focus on Transformer models, machine translation, or the attention mechanism in neural networks to provide the structured JSON information for similar papers. Please note, I will utilize external sources online to find related academic papers.\n",
      "I apologize for any confusion, but as a language model, my capabilities are such that I cannot search for and provide exact links to papers on external databases directly. Nonetheless, I can guide you on how to find similar papers using common academic databases and search engines.\n",
      "\n",
      "To search for similar papers, you can use academic databases such as Google Scholar (scholar.google.com), arXiv (arxiv.org), IEEE Xplore (ieeexplore.ieee.org), or PubMed (pubmed.ncbi.nlm.nih.gov), among others. When you search for papers related to \"Attention Is All You Need\" by Vaswani et al., use keywords that are central to the paper's topic such as \"Transformer models,\" \"machine translation,\" \"neural networks,\" \"attention mechanisms,\" and \"sequence transduction.\"\n",
      "\n",
      "Here is an example of how you can structure your JSON manually based on papers you find that are related to \"Attention Is All You Need:\"\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"paper_title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n",
      "    \"authors_names\": [\"Jacob Devlin\", \"Ming-Wei Chang\", \"Kenton Lee\", \"Kristina Toutanova\"],\n",
      "    \"publication_date\": \"2018\",\n",
      "    \"link_of_paper\": \"https://arxiv.org/abs/1810.04805\",\n",
      "    \"conference_or_journal_name\": \"NAACL 2019\"\n",
      "  },\n",
      "  {\n",
      "    \"paper_title\": \"Universal Transformers\",\n",
      "    \"authors_names\": [\"Mostafa Dehghani\", \"Stephan Gouws\", \"Oriol Vinyals\", \"Jakob Uszkoreit\", \"Łukasz Kaiser\"],\n",
      "    \"publication_date\": \"2018\",\n",
      "    \"link_of_paper\": \"https://arxiv.org/abs/1807.03819\",\n",
      "    \"conference_or_journal_name\": \"ICLR 2019\"\n",
      "  },\n",
      "  // ... additional entries\n",
      "]\n",
      "```\n",
      "\n",
      "To compose a JSON file similar to the example above, search for each paper on an academic database, confirm that they are relevant to the topic of interest, and then extract their metadata, which includes the title, authors, publication date, link, and publishing venue. Please proceed by using these steps on an external database. If you would like, I can demonstrate how the search function works with a generic example query.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "In this tutorial, we learned about OpenAI Assistant and how it can help us make smart programs. We saw how to use it with LangChain tools to create helpful assistants for different tasks.\n",
    "\n",
    "First, we talked about OpenAI Assistant and what it can do, like giving smart answers in apps using special tools.\n",
    "\n",
    "Then, we looked at examples. We made a helper called ScholarlySphere that can understand documents and find more info online. We did this by making an assistant with LangChain's tools.\n",
    "\n",
    "Next, we showed how to use OpenAI Assistant with LangChain to summarize a document and find similar ones. We made an assistant that can read a document, summarize it, and find other documents like it online.\n",
    "\n",
    "By doing these examples, we saw how OpenAI Assistant can do many things, from reading documents to finding info online, and how we can use it with LangChain for even more power. Overall, this tutorial showed us how to make smart programs with AI helpers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxonomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
